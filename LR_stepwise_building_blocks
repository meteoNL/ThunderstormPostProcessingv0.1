########################################
#This is without any transformations!!!#
#For now, sample climatology is used!!!#
########################################



#### BUILD IN SOME TESTING!!!!!


#rm(list=ls(all=TRUE))
### LOAD EXTERNAL CODE
library(dplyr)
library(MASS)
library(verification)
library(devtools)
library(testthat)
usethis::use_testthat()

### SET GENERAL CONDITIONS FOR THE MODEL
#read dataset
ObsPV = readRDS(file = "/usr/people/whan/Research/Whanetal_HarmoniePr_2017/data/ObsPV.rds")
years = c(as.numeric(unique(ObsPV$Year)))
LT = c(as.numeric(unique(ObsPV$leadtime_count)))[1]
VT = c(unique(ObsPV$validtime))[2]
regions = c(unique(ObsPV$region))
threshold = 3.00

#set default available variables: predictant and predictor
numsubset = 3 #number of subsets for hyperparametersetting
ind_predictant = 6
varindex=seq(16,99)
pot_preds=names(ObsPV[varindex])
ndec = 4
maxsteps = 6

verify_LRmodel_per_reg <- function(train_set, test_set, model, region_set, predictant, nstepsAIC, thres, reliabilityplot = FALSE){
  briers = c()

  if (length(train_set) != length(test_set)){
    message("Training and test sets have to have the same number of columns")
    return("Failed")
  }
  for (reg in region_set){
    region_subset = filter(test_set, region == reg)
    observed = as.numeric(region_subset[predictant] > thres)
    values <- predict(model, newdata = region_subset)
    probability = exp(values)/(1+exp(values))
    last_brier = brier(observed, probability, bins = FALSE)$bs #alternative with bins - - verification_set$bs
    briers = append(briers, c(y, nstepsAIC, reg, round(last_brier, ndec)))
    if(reliabilityplot == TRUE){
      verification_set <- verify(observed, probability, frcst.type = "prob", obs.type = "binary", title = )

      #visualize skill
      reliability.plot(verification_set, titl = paste("Number of predictors = ", (nstepsAIC), " - Brier score = ", round(last_brier,ndec), " & region = ", reg), legend.names = paste(logitMod$formula[3]))

    }
  }
  return(briers)

}

fit_logitModels_and_predict <- function(train_set, test_set, region_set = regions, predictant = ind_predictant, pot_pred_indices = varindex,
                         thres = threshold, maxstepsAIC = 10, print_conf = FALSE){

  if(maxstepsAIC > length(pot_pred_indices)){
    message("You can not add more variables to the model than the number of available predictors")
    return("Failed")
  }

  #do the reference fit
  nullfit = glm(unlist(train_set[predictant] > thres) ~ 1, data = train_set[pot_pred_indices], family=binomial)

  #results storage
  modellist = list()
  briers = c()
  results = list()

  #stepwise LR model fitting
  for (nstepsAIC in seq(maxstepsAIC)){
    logitMod = stepAIC(nullfit, scope = list(upper = lm(unlist(train_set[predictant] > thres) ~ .,
                                                        data=train_set[pot_pred_indices]),
                                                        lower = ~ 1), trace = 0, steps=nstepsAIC)
    if(print_conf == TRUE){
      conf=exp(confint.default(logitMod))
      print(conf)
    }

    verification_result = verify_LRmodel_per_reg(train_set, test_set, logitMod, region_set, predictant, nstepsAIC, thres, reliabilityplot = FALSE)

    #make lists of model, probabilities and brier scores including skill score
    modellist = append(modellist,list(logitMod))
    briers = append(briers, verification_result)
  }
  if("Failed" %in% briers){
    return("Failed")
  }

  #returned values
  results$model = modellist
  results$briers = briers
  results$nullfit = list(nullfit)
  return(results)
}

#create memory for models and their evaluation
brierdataframe = data.frame()
models = list()
nullfits = list()
for(y in years){

  #create random subsets to train on
  train = filter(ObsPV, Year != y & validtime == VT & leadtime_count == LT)
  randomsubset = round(runif(nrow(train))*numsubset+0.5)
  train_sub = cbind(train,subset = randomsubset)

  for(j in seq(numsubset)){
    #check approximately equal length of random subsets by printing relative length
    relweight_subset = sum(train_sub$subset[train_sub$subset == j])/nrow(train_sub)/j
    print(relweight_subset)
    print(j)

    #select training and testing dataset
    train_j = filter(train_sub, subset != j)[seq(length(ObsPV))]
    test_j = filter(train_sub, subset == j)[seq(length(ObsPV))]

    #find a fit
    result = fit_logitModels_and_predict(train = train_j, test = test_j, region_set = regions, predictant = ind_predictant, pot_pred_indices = varindex, thres = threshold, maxstepsAIC = maxsteps, print_conf = FALSE)

    #put results in dataframes and vectors
    brierdataframe = rbind(brierdataframe, data.frame(test_year = (result$briers)[seq(1,length(result$briers),4)],
                                                      npredictors = (result$briers)[seq(2,length(result$briers),4)],
                                                      region = (result$briers)[seq(3,length(result$briers),4)],
                                                      brier_score = (result$briers)[seq(4,length(result$briers),4)]))
    models = append(models, result$model)
    nullfits = append(nullfits, result$nullfit)
  }
}

# aggragate scores to get a graph as function of number of predictors
new_brierdataframe = brierdataframe[order(brierdataframe$npredictors),]
scores = t(matrix(c(new_brierdataframe$brier_score), nrow = (numsubset*length(years)*length(regions)), ncol = (maxsteps)))
meanscores = rowMeans(scores)
matplot(scores, type = "o", xlab = "Number of predictors (-)", ylab = "Brier score (-)")
plot(meanscores, xlab = "Number of predictors (-)", ylab = "Mean brier score (-)")

for(y in years){
  train_fin = filter(ObsPV, Year != y & validtime == VT & leadtime_count == LT)
  test_fin = filter(ObsPV, Year == y & validtime == VT & leadtime_count == LT)
  result = fit_logitModels_and_predict(train_set = train_fin, test_set = test_fin,
                                       predictant = ind_predictant, pot_pred_indices = varindex,
                                       thres = 3.00, maxstepsAIC = maxsteps, print_conf = FALSE)
  brierdataframe = rbind(brierdataframe, data.frame(test_year = (result$briers)[seq(1,length(result$briers),4)],
                                                    npredictors = (result$briers)[seq(2,length(result$briers),4)],
                                                    region = (result$briers)[seq(3,length(result$briers),4)],
                                                    brier_score = (result$briers)[seq(4,length(result$briers),4)]))
  models = append(models, result$model)
  nullfits = append(nullfits, result$nullfit)
}

# --------------------------------------------------
test_that("Test dataset complete?", {
  expect_equal(filter(ObsPV, validtime == VT & leadtime_count == LT), rbind(train_fin, test_fin))
  })

test_that("Test resulting brier data frame for obvious errors",{
  expect_equal(unique(brierdataframe$region), regions)
  expect_equal(unique(brierdataframe$test_year), years)
  expect_gte(min(brierdataframe$npredictors),1)
  expect_lte(min(brierdataframe$npredictors),maxsteps)
  expect_gte(min(brierdataframe$brier_score),0)
  expect_lte(min(brierdataframe$brier_score),1)
  expect_equal(rep(regions,length(brierdataframe$region)/(length(regions))), brierdataframe$region)
 # expect_gte(min(brierdataframe$brier_base),0)
 # expect_lte(min(brierdataframe$brier_base),1)
})
set.seed(228)
x1 = rnorm(500,0,5)
x2 = rnorm(500,0,5)
x3 = rnorm(500,0,5)
x4 = rnorm(500,0,5)
pert = rnorm(500,0,10)
y1 = x1*100+x4*10+pert
testthat_dfLR = data.frame(y1,x1,x2,x3,x4, region = 1)
test_model = fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = c(2,5),
                                        thres = threshold, maxstepsAIC = 2, print_conf = FALSE)$model[[1]]
test_that("Function fit_logitModels_and_predict",{
  expect_equal(fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = seq(2,5),
                                                                                                              thres = threshold, maxstepsAIC = 2, print_conf = FALSE)[[1]][[1]][1:24],
               fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = c(2,5),
                                                                                                              thres = threshold, maxstepsAIC = 2, print_conf = FALSE)[[1]][[1]][1:24]) ## at index 25, the data frame used for fitting is in the result; these should be different
  expect_equal(fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = c(2,5),
                              thres = threshold, maxstepsAIC = 3, print_conf = FALSE),"Failed") ## at index 25, the data frame used for fitting is in the result; these should be different
  expect_error(fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = c(2,190),
                                           thres = threshold, maxstepsAIC = 2, print_conf = FALSE))
  expect_error(fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(3), 1, pot_pred_indices = c(2,190),
                                           thres = threshold, maxstepsAIC = 2, print_conf = FALSE))
  expect_error(fit_logitModels_and_predict(train_j, testthat_dfLR, region_set = c(3), 1, pot_pred_indices = c(2,5),
                                           thres = threshold, maxstepsAIC = 2, print_conf = FALSE))
  expect_equal(fit_logitModels_and_predict(testthat_dfLR, train_j, region_set = c(3), 1, pot_pred_indices = c(2,5),
                                           thres = threshold, maxstepsAIC = 2, print_conf = FALSE),"Failed") #wrong verification dataframe

})

test_model2 = fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = seq(2,5),thres = 1, maxstepsAIC = 2, print_conf = FALSE)$model[[2]]
values = 0.04868986 + 4.18488448 * x1
test_that("verify_LRmodel_per_reg works",{
  expect_equal(verify_LRmodel_per_reg(testthat_dfLR, testthat_dfLR, test_model, c(1), 1, 1, 1, reliabilityplot = FALSE)[4],brier((testthat_dfLR$y1 > 1),(exp(values) / (1+exp(values))), bins = FALSE)$bs, 1e-3)
  expect_equal(verify_LRmodel_per_reg(testthat_dfLR, testthat_dfLR, test_model2, c(1), 1, 1, 1, reliabilityplot = FALSE)[4],fit_logitModels_and_predict(testthat_dfLR, testthat_dfLR, region_set = c(1), 1, pot_pred_indices = seq(2,5),
                                                                                                                                                                                                                                           thres = 1, maxstepsAIC = 2, print_conf = FALSE)$brier[[8]], 1e-3)
  expect_warning(verify_LRmodel_per_reg(train_j, train_j, test_model2, c(1), 1, 1, 1, reliabilityplot = FALSE)[4])
  expect_error(verify_LRmodel_per_reg(testthat_dfLR, testthat_dfLR, test_model2, c(1),  38, 1, 1, reliabilityplot = FALSE))

})
